{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac380ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Dataset.Dataset import get_tokenizer\n",
    "from Model.Model import SLMModel\n",
    "from tokenizers import Tokenizer\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f58849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2409ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 256\n",
    "VOCAB_SIZE =10000\n",
    "EMBEDDING_DIM = 512\n",
    "\n",
    "tokenizer = get_tokenizer(config[\"tokenizer_path\"],MAX_SEQ_LEN)\n",
    "tokenizer.no_truncation()\n",
    "tokenizer.no_padding()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = SLMModel(VOCAB_SIZE,EMBEDDING_DIM,4,8,64,64,0.1,1024,0.2)\n",
    "model.load_state_dict(torch.load(config[\"best_model_state_dict\"]))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11063f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model: torch.nn.Module, tokenizer: Tokenizer, prompt, max_seq_len, device: torch.device, temperature=1.):\n",
    "    model.eval()  \n",
    "    \n",
    "    tokens = tokenizer.encode(prompt).ids\n",
    "    tokenized_tokens = torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0) \n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for i in range(max_seq_len - len(tokens)):\n",
    "            \n",
    "            preds = model(tokenized_tokens)\n",
    "    \n",
    "            last_token_logits = preds[0, -1, :] \n",
    "            \n",
    "            probs = torch.softmax(last_token_logits / temperature, dim=-1)\n",
    "            \n",
    "            next_token_id = torch.multinomial(probs, 1)\n",
    "            \n",
    "            tokenized_tokens = torch.cat([\n",
    "                tokenized_tokens, \n",
    "                next_token_id.unsqueeze(0)\n",
    "            ], dim=1)\n",
    "            \n",
    "            if next_token_id.item() == tokenizer.token_to_id(\"[END]\"):\n",
    "                print(\"the generation was stopped due to the [END] token\")\n",
    "                break\n",
    "            \n",
    "\n",
    "    generated_tokens = tokenized_tokens.squeeze(0).tolist()\n",
    "    generated_text = tokenizer.decode(generated_tokens)\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00e89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the generation was stopped due to the [END] token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The little dragon was afraid of fire because it was so big and frightening . He sighed when he saw a big box in the back yard . It was made of wood and had a shiny lock on it . Suddenly , the dragon saw a bright light coming from inside the box . It flew out and into the house . The dragon paused and looked back . He saw his human , who was playing catch with a ball . The dragon smiled and waved at the human , who waved back . The human smiled back and the dragon hopped in and started to play a game of catch . The dragon was so happy that he started to laugh . He dropped the ball on the ground and jumped up and down . Suddenly , the dragon heard his mom \\' s voice . She rushed outside and saw him . She said to his mom , \" What are you doing ?\" The dragon just sighed and said , \" Playing catch is much more fun than catching fire .\" His mom laughed again . She knew that the dragon was harmless and it was just trying to be fun . The little dragon smiled , grabbed the ball and ran off to play with his new friend .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"[START] \" #Insert your prompt\n",
    "generate_text(model,tokenizer,prompt,MAX_SEQ_LEN,device,0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
