{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e8e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas\n",
    "from Dataset.Dataset import get_tokenizer, get_dataset_loader\n",
    "from Model.Model import SLMModel\n",
    "import torchinfo\n",
    "from tqdm import tqdm\n",
    "from Model.GradViewer import GradViewer\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe64fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a759e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 512\n",
    "MAX_SEQ_LEN = 256\n",
    "VOCAB_SIZE =10000\n",
    "LR_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6513dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_path = config[\"data\"][\"train_path\"]\n",
    "val_ds_path = config[\"data\"][\"val_path\"]\n",
    "\n",
    "train_df = pandas.read_parquet(train_ds_path)\n",
    "val_df = pandas.read_parquet(val_ds_path)\n",
    "\n",
    "tokenizer = get_tokenizer(config[\"tokenizer_path\"],MAX_SEQ_LEN)\n",
    "\n",
    "train_dataloader = get_dataset_loader(train_df,tokenizer,\"train_dataset_cache.pth\",BATCH_SIZE,True,4,2)\n",
    "val_dataloader = get_dataset_loader(val_df,tokenizer,\"val_dataset_cache.pth\",BATCH_SIZE,False,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14330d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = SLMModel(VOCAB_SIZE,EMBEDDING_DIM,4,8,64,64,0.1,1024,0.2)\n",
    "model = model.to(device)\n",
    "compiled_model = torch.compile(model,mode=\"default\",dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5958510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "SLMModel                                      [64, 256, 10000]          --\n",
       "├─Embedding: 1-1                              [64, 256, 512]            5,120,000\n",
       "├─SinusoidalPositionalEmbedding: 1-2          [64, 256, 512]            --\n",
       "├─ModuleList: 1-3                             --                        --\n",
       "│    └─TransformerBlock: 2-1                  [64, 256, 512]            --\n",
       "│    │    └─RMSNorm: 3-1                      [64, 256, 512]            512\n",
       "│    │    └─FlashMultiHeadAttention: 3-2      [64, 256, 512]            1,050,624\n",
       "│    │    └─RMSNorm: 3-3                      [64, 256, 512]            512\n",
       "│    │    └─RMSNorm: 3-4                      [64, 256, 512]            512\n",
       "│    │    └─FeedForwardBlock: 3-5             [64, 256, 512]            1,575,424\n",
       "│    │    └─RMSNorm: 3-6                      [64, 256, 512]            512\n",
       "│    └─TransformerBlock: 2-2                  [64, 256, 512]            --\n",
       "│    │    └─RMSNorm: 3-7                      [64, 256, 512]            512\n",
       "│    │    └─FlashMultiHeadAttention: 3-8      [64, 256, 512]            1,050,624\n",
       "│    │    └─RMSNorm: 3-9                      [64, 256, 512]            512\n",
       "│    │    └─RMSNorm: 3-10                     [64, 256, 512]            512\n",
       "│    │    └─FeedForwardBlock: 3-11            [64, 256, 512]            1,575,424\n",
       "│    │    └─RMSNorm: 3-12                     [64, 256, 512]            512\n",
       "│    └─TransformerBlock: 2-3                  [64, 256, 512]            --\n",
       "│    │    └─RMSNorm: 3-13                     [64, 256, 512]            512\n",
       "│    │    └─FlashMultiHeadAttention: 3-14     [64, 256, 512]            1,050,624\n",
       "│    │    └─RMSNorm: 3-15                     [64, 256, 512]            512\n",
       "│    │    └─RMSNorm: 3-16                     [64, 256, 512]            512\n",
       "│    │    └─FeedForwardBlock: 3-17            [64, 256, 512]            1,575,424\n",
       "│    │    └─RMSNorm: 3-18                     [64, 256, 512]            512\n",
       "│    └─TransformerBlock: 2-4                  [64, 256, 512]            --\n",
       "│    │    └─RMSNorm: 3-19                     [64, 256, 512]            512\n",
       "│    │    └─FlashMultiHeadAttention: 3-20     [64, 256, 512]            1,050,624\n",
       "│    │    └─RMSNorm: 3-21                     [64, 256, 512]            512\n",
       "│    │    └─RMSNorm: 3-22                     [64, 256, 512]            512\n",
       "│    │    └─FeedForwardBlock: 3-23            [64, 256, 512]            1,575,424\n",
       "│    │    └─RMSNorm: 3-24                     [64, 256, 512]            512\n",
       "├─RMSNorm: 1-4                                [64, 256, 512]            512\n",
       "├─Linear: 1-5                                 [64, 256, 10000]          5,130,000\n",
       "===============================================================================================\n",
       "Total params: 20,762,896\n",
       "Trainable params: 20,762,896\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.33\n",
       "===============================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 4934.60\n",
       "Params size (MB): 83.05\n",
       "Estimated Total Size (MB): 5017.78\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model,input_data=torch.randint(0,VOCAB_SIZE,(BATCH_SIZE,MAX_SEQ_LEN),device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f720cb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),LR_RATE)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',           \n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    threshold=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "grad_scaler = torch.GradScaler()\n",
    "grad_viewer = GradViewer(model,\"SLM L2 norm grads\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6244e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,saved_model: torch.nn.Module, num_epochs, train_loader, val_loader, \n",
    "          optimizer, loss_fn, device,scheduler=None, grad_scaler=None):\n",
    "    \n",
    "    best_val_loss=0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader):\n",
    "            inputs, targets = batch  \n",
    "            inputs = inputs.to(device)  \n",
    "            targets = targets.to(device)  \n",
    "            \n",
    "            batch_size = inputs.shape[0]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "           \n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                preds = model(inputs)\n",
    "                \n",
    "               \n",
    "                loss = loss_fn(\n",
    "                    preds.reshape((-1,VOCAB_SIZE)), \n",
    "                    targets.reshape((-1,))\n",
    "                )\n",
    "            \n",
    "            \n",
    "            if grad_scaler:\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_viewer.view_grad()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "    \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                batch_size = inputs.shape[0]\n",
    "                preds = model(inputs)\n",
    "                loss = loss_fn(\n",
    "                    preds.reshape((-1,VOCAB_SIZE)),\n",
    "                    targets.reshape((-1,))\n",
    "                )\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train loss: {train_loss/len(train_loader):.4f}\")\n",
    "        print(f\"Val loss: {val_loss/len(val_loader):.4f}\")\n",
    "        print(f\"Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "        \n",
    "\n",
    "        if best_val_loss is None or best_val_loss > avg_val_loss:\n",
    "            torch.save(saved_model.state_dict(),f\"best_model_st{epoch+1}.pt\")\n",
    "            print(f\"Модель сохранена на эпохе: {epoch+1}\")\n",
    "            best_val_loss = avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1422e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(compiled_model,model,50,train_dataloader,val_dataloader,optimizer,loss_fn,device,scheduler,grad_scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
